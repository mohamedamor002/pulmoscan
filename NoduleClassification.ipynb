{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11439543,"sourceType":"datasetVersion","datasetId":7165914}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.applications import Xception, InceptionResNetV2, MobileNetV2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.constraints import max_norm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.384929Z","iopub.execute_input":"2025-04-25T16:20:50.385474Z","iopub.status.idle":"2025-04-25T16:20:50.390301Z","shell.execute_reply.started":"2025-04-25T16:20:50.385453Z","shell.execute_reply":"2025-04-25T16:20:50.389540Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"\n# ---------------------- DATA PREPARATION ----------------------\n# Load and prepare data\ndf = pd.read_csv('/kaggle/input/labels/dataset_with_image_links.csv')\navailable_subjects = [d for d in os.listdir('/kaggle/working/lidc_train_test') \n                    if os.path.isdir(os.path.join('/kaggle/working/lidc_train_test', d))]\ndf = df[df['Subject ID'].isin(available_subjects)]\ndf['Image_Link'] = df['Image_Link'].str.replace('/kaggle/input/lidcidri/LIDC-IDRI-slices/', '/kaggle/working/lidc_train_test/')\n\n# Split data\ntrain_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Cancer_Label'], random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Cancer_Label'], random_state=42)\n\ndef create_image_df(df):\n    image_paths = []\n    labels = []\n    for _, row in df.iterrows():\n        image_dir = row['Image_Link']\n        if not os.path.exists(image_dir):\n            continue\n        label = row['Cancer_Label']\n        for file in os.listdir(image_dir):\n            if file.endswith(('.png', '.jpg')):\n                image_paths.append(os.path.join(image_dir, file))\n                labels.append(label)\n    return pd.DataFrame({'image_path': image_paths, 'label': labels})\n\ntrain_images = create_image_df(train_df)\nval_images = create_image_df(val_df)\ntest_images = create_image_df(test_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.391507Z","iopub.execute_input":"2025-04-25T16:20:50.391753Z","iopub.status.idle":"2025-04-25T16:20:50.637300Z","shell.execute_reply.started":"2025-04-25T16:20:50.391733Z","shell.execute_reply":"2025-04-25T16:20:50.636755Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# ---------------------- CLASS BALANCING ----------------------\nclass_weights = compute_class_weight('balanced', \n                                   classes=np.unique(train_images['label']), \n                                   y=train_images['label'])\nclass_weights = dict(enumerate(class_weights))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.638464Z","iopub.execute_input":"2025-04-25T16:20:50.638816Z","iopub.status.idle":"2025-04-25T16:20:50.645243Z","shell.execute_reply.started":"2025-04-25T16:20:50.638789Z","shell.execute_reply":"2025-04-25T16:20:50.644468Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# ---------------------- ENHANCED DATA AUGMENTATION ----------------------\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='nearest'\n)\n\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_images,\n    x_col='image_path',\n    y_col='label',\n    target_size=(256, 256),\n    batch_size=32,\n    class_mode='raw',\n    shuffle=True\n)\n\nval_generator = val_test_datagen.flow_from_dataframe(\n    dataframe=val_images,\n    x_col='image_path',\n    y_col='label',\n    target_size=(256, 256),\n    batch_size=32,\n    class_mode='raw',\n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.646220Z","iopub.execute_input":"2025-04-25T16:20:50.646512Z","iopub.status.idle":"2025-04-25T16:20:50.744335Z","shell.execute_reply.started":"2025-04-25T16:20:50.646489Z","shell.execute_reply":"2025-04-25T16:20:50.743644Z"}},"outputs":[{"name":"stdout","text":"Found 9837 validated image filenames.\nFound 2067 validated image filenames.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"\n# ---------------------- MODEL ARCHITECTURE ----------------------\ndef create_model(base_model, fine_tune=False):\n    # Freeze base model initially\n    base_model.trainable = False\n    \n    # Unfreeze top layers for fine-tuning\n    if fine_tune:\n        base_model.trainable = True\n        for layer in base_model.layers[:-20]:\n            layer.trainable = False\n            \n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    x = Dropout(0.6)(x)\n    x = Dense(128, activation='relu', \n             kernel_regularizer=l2(0.01),\n             kernel_constraint=max_norm(3))(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.6)(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    return Model(inputs=base_model.input, outputs=outputs)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.746050Z","iopub.execute_input":"2025-04-25T16:20:50.746236Z","iopub.status.idle":"2025-04-25T16:20:50.751468Z","shell.execute_reply.started":"2025-04-25T16:20:50.746222Z","shell.execute_reply":"2025-04-25T16:20:50.750664Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"def get_callbacks(model_name):\n    return [\n        EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, mode='max'),\n        ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6),\n        ModelCheckpoint(f'best_{model_name}.keras', save_best_only=True)  # Changed to .keras\n    ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.752152Z","iopub.execute_input":"2025-04-25T16:20:50.752445Z","iopub.status.idle":"2025-04-25T16:20:50.765914Z","shell.execute_reply.started":"2025-04-25T16:20:50.752429Z","shell.execute_reply":"2025-04-25T16:20:50.765242Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"\n# ---------------------- TRAINING PIPELINE ----------------------\ndef train_model(base_model, model_name):\n    # Phase 1: Feature extraction\n    model = create_model(base_model)\n    model.compile(optimizer='adam',\n                loss='sparse_categorical_crossentropy',\n                metrics=['accuracy'])\n    \n    print(f\"\\nPhase 1: Feature Extraction ({model_name})\")\n    history = model.fit(\n        train_generator,\n        epochs=50,\n        validation_data=val_generator,\n        class_weight=class_weights,\n        callbacks=get_callbacks(model_name)\n    )\n    \n    # Phase 2: Fine-tuning\n    print(f\"\\nPhase 2: Fine-Tuning ({model_name})\")\n    fine_tune_model = create_model(base_model, fine_tune=True)\n    fine_tune_model.set_weights(model.get_weights())\n    \n    fine_tune_model.compile(\n        optimizer=tf.keras.optimizers.Adam(1e-5),\n        loss='sparse_categorical_crossentropy',\n        metrics=['accuracy']\n    )\n    \n    history_fine = fine_tune_model.fit(\n        train_generator,\n        epochs=30,\n        initial_epoch=history.epoch[-1],\n        validation_data=val_generator,\n        class_weight=class_weights,\n        callbacks=get_callbacks(f'{model_name}_fine')\n    )\n    \n    # Combine histories\n    combined_history = {\n        'accuracy': history.history['accuracy'] + history_fine.history['accuracy'],\n        'val_accuracy': history.history['val_accuracy'] + history_fine.history['val_accuracy'],\n        'loss': history.history['loss'] + history_fine.history['loss'],\n        'val_loss': history.history['val_loss'] + history_fine.history['val_loss']\n    }\n    \n    return fine_tune_model, combined_history\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.766899Z","iopub.execute_input":"2025-04-25T16:20:50.767134Z","iopub.status.idle":"2025-04-25T16:20:50.785775Z","shell.execute_reply.started":"2025-04-25T16:20:50.767114Z","shell.execute_reply":"2025-04-25T16:20:50.785144Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"\n# ---------------------- MODEL TRAINING ----------------------\n# Initialize base models with correct input shapes\nxception_base = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\ninception_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\nmobilenet_base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Updated shape\n\n# MobileNet-specific generator (224x224)\nmobilenet_train_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_images,\n    x_col='image_path',\n    y_col='label',\n    target_size=(224, 224),  # Adjusted size\n    batch_size=32,\n    class_mode='raw',\n    shuffle=True\n)\n\nmobilenet_val_generator = val_test_datagen.flow_from_dataframe(\n    dataframe=val_images,\n    x_col='image_path',\n    y_col='label',\n    target_size=(224, 224),  # Adjusted size\n    batch_size=32,\n    class_mode='raw',\n    shuffle=False\n)\n# Train models with appropriate generators\nxception_model, xception_history = train_model(xception_base, 'Xception')\ninception_model, inception_history = train_model(inception_base, 'InceptionResNetV2')\nmobilenet_model, mobilenet_history = train_model(\n    mobilenet_base, \n    'MobileNetV2',\n    train_generator=mobilenet_train_generator,  # Pass custom generators\n    val_generator=mobilenet_val_generator\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T16:20:50.786469Z","iopub.execute_input":"2025-04-25T16:20:50.786705Z","iopub.status.idle":"2025-04-25T17:47:47.041652Z","shell.execute_reply.started":"2025-04-25T16:20:50.786682Z","shell.execute_reply":"2025-04-25T17:47:47.040509Z"}},"outputs":[{"name":"stdout","text":"Found 9837 validated image filenames.\nFound 2067 validated image filenames.\n\nPhase 1: Feature Extraction (Xception)\nEpoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 493ms/step - accuracy: 0.5055 - loss: 3.1114 - val_accuracy: 0.2284 - val_loss: 2.0846 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 451ms/step - accuracy: 0.5613 - loss: 1.6022 - val_accuracy: 0.2912 - val_loss: 1.4590 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 451ms/step - accuracy: 0.5852 - loss: 1.1924 - val_accuracy: 0.4436 - val_loss: 1.1038 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 444ms/step - accuracy: 0.5922 - loss: 1.0059 - val_accuracy: 0.1708 - val_loss: 1.2330 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 449ms/step - accuracy: 0.5852 - loss: 0.9467 - val_accuracy: 0.7441 - val_loss: 0.8111 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 447ms/step - accuracy: 0.5789 - loss: 0.8961 - val_accuracy: 0.2700 - val_loss: 1.0157 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 452ms/step - accuracy: 0.5863 - loss: 0.8649 - val_accuracy: 0.6899 - val_loss: 0.7999 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 449ms/step - accuracy: 0.5950 - loss: 0.8569 - val_accuracy: 0.4349 - val_loss: 0.9161 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 448ms/step - accuracy: 0.5894 - loss: 0.8208 - val_accuracy: 0.2172 - val_loss: 1.0250 - learning_rate: 0.0010\nEpoch 10/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 445ms/step - accuracy: 0.5747 - loss: 0.8325 - val_accuracy: 0.4915 - val_loss: 0.8416 - learning_rate: 2.0000e-04\n\nPhase 2: Fine-Tuning (Xception)\nEpoch 10/30\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1745599511.786437      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1745599511.933810      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1745599512.722304      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1745599512.862132      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1745599513.216903      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1745599513.367287      93 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 481ms/step - accuracy: 0.5765 - loss: 0.9061 - val_accuracy: 0.4906 - val_loss: 0.9310 - learning_rate: 1.0000e-05\nEpoch 11/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 457ms/step - accuracy: 0.5827 - loss: 0.8523 - val_accuracy: 0.5448 - val_loss: 0.8838 - learning_rate: 1.0000e-05\nEpoch 12/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 457ms/step - accuracy: 0.5921 - loss: 0.8283 - val_accuracy: 0.5385 - val_loss: 0.8866 - learning_rate: 1.0000e-05\nEpoch 13/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 458ms/step - accuracy: 0.5904 - loss: 0.8174 - val_accuracy: 0.4886 - val_loss: 0.9129 - learning_rate: 1.0000e-05\nEpoch 14/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 455ms/step - accuracy: 0.6073 - loss: 0.8127 - val_accuracy: 0.4640 - val_loss: 0.9281 - learning_rate: 2.0000e-06\nEpoch 15/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 455ms/step - accuracy: 0.5987 - loss: 0.8190 - val_accuracy: 0.4717 - val_loss: 0.9257 - learning_rate: 2.0000e-06\nEpoch 16/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 456ms/step - accuracy: 0.5967 - loss: 0.8024 - val_accuracy: 0.4799 - val_loss: 0.9174 - learning_rate: 1.0000e-06\n\nPhase 1: Feature Extraction (InceptionResNetV2)\nEpoch 1/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 579ms/step - accuracy: 0.5116 - loss: 3.1671 - val_accuracy: 0.0963 - val_loss: 3.0615 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 478ms/step - accuracy: 0.5473 - loss: 1.8815 - val_accuracy: 0.4035 - val_loss: 1.5379 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 473ms/step - accuracy: 0.5735 - loss: 1.3576 - val_accuracy: 0.5839 - val_loss: 1.1486 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 476ms/step - accuracy: 0.5916 - loss: 1.0762 - val_accuracy: 0.1214 - val_loss: 1.5358 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 484ms/step - accuracy: 0.6146 - loss: 0.9563 - val_accuracy: 0.4107 - val_loss: 1.0407 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 481ms/step - accuracy: 0.5979 - loss: 0.9004 - val_accuracy: 0.9129 - val_loss: 0.5591 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 467ms/step - accuracy: 0.6036 - loss: 0.8379 - val_accuracy: 0.4098 - val_loss: 0.9679 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 486ms/step - accuracy: 0.6162 - loss: 0.8106 - val_accuracy: 0.7102 - val_loss: 0.7632 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 486ms/step - accuracy: 0.5784 - loss: 0.8129 - val_accuracy: 0.8631 - val_loss: 0.6305 - learning_rate: 2.0000e-04\nEpoch 10/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 473ms/step - accuracy: 0.6004 - loss: 0.7800 - val_accuracy: 0.5612 - val_loss: 0.7895 - learning_rate: 2.0000e-04\nEpoch 11/50\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 462ms/step - accuracy: 0.6107 - loss: 0.7388 - val_accuracy: 0.5549 - val_loss: 0.7866 - learning_rate: 4.0000e-05\n\nPhase 2: Fine-Tuning (InceptionResNetV2)\nEpoch 11/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 575ms/step - accuracy: 0.5728 - loss: 0.8692 - val_accuracy: 0.6294 - val_loss: 0.8378 - learning_rate: 1.0000e-05\nEpoch 12/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 478ms/step - accuracy: 0.5855 - loss: 0.8398 - val_accuracy: 0.5525 - val_loss: 0.8778 - learning_rate: 1.0000e-05\nEpoch 13/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 474ms/step - accuracy: 0.5866 - loss: 0.8252 - val_accuracy: 0.5181 - val_loss: 0.8938 - learning_rate: 1.0000e-05\nEpoch 14/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 478ms/step - accuracy: 0.5949 - loss: 0.7975 - val_accuracy: 0.5172 - val_loss: 0.8905 - learning_rate: 2.0000e-06\nEpoch 15/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 467ms/step - accuracy: 0.6014 - loss: 0.8030 - val_accuracy: 0.5283 - val_loss: 0.8869 - learning_rate: 2.0000e-06\nEpoch 16/30\n\u001b[1m308/308\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 466ms/step - accuracy: 0.5969 - loss: 0.8089 - val_accuracy: 0.5269 - val_loss: 0.8880 - learning_rate: 1.0000e-06\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2040587670.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mxception_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxception_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxception_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Xception'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0minception_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minception_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'InceptionResNetV2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m mobilenet_model, mobilenet_history = train_model(\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mmobilenet_base\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m'MobileNetV2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: train_model() got an unexpected keyword argument 'train_generator'"],"ename":"TypeError","evalue":"train_model() got an unexpected keyword argument 'train_generator'","output_type":"error"}],"execution_count":42},{"cell_type":"code","source":"# ---------------------- VISUALIZATION ----------------------\ndef plot_metrics(history, model_name):\n    plt.figure(figsize=(12, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(history['accuracy'], label='Train')\n    plt.plot(history['val_accuracy'], label='Validation')\n    plt.title(f'{model_name} Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history['loss'], label='Train')\n    plt.plot(history['val_loss'], label='Validation')\n    plt.title(f'{model_name} Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'{model_name}_metrics.png')\n    plt.show()\n\nplot_metrics(xception_history, 'Xception')\nplot_metrics(inception_history, 'InceptionResNetV2')\nplot_metrics(mobilenet_history, 'MobileNetV2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T17:47:47.042326Z","iopub.status.idle":"2025-04-25T17:47:47.042671Z","shell.execute_reply.started":"2025-04-25T17:47:47.042488Z","shell.execute_reply":"2025-04-25T17:47:47.042501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------- MODEL EVALUATION ----------------------\ndef evaluate_model(model, generator):\n    results = model.evaluate(generator)\n    print(f\"Loss: {results[0]:.4f} - Accuracy: {results[1]:.4f}\")\n\nprint(\"\\nXception Evaluation:\")\nevaluate_model(xception_model, val_generator)\n\nprint(\"\\nInceptionResNetV2 Evaluation:\")\nevaluate_model(inception_model, val_generator)\n\nprint(\"\\nMobileNetV2 Evaluation:\")\nevaluate_model(mobilenet_model, val_generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T17:47:47.043646Z","iopub.status.idle":"2025-04-25T17:47:47.043880Z","shell.execute_reply.started":"2025-04-25T17:47:47.043770Z","shell.execute_reply":"2025-04-25T17:47:47.043778Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------- MODEL SAVING ----------------------\nxception_model.save('xception_finall.h5')\ninception_model.save('inception_finall.h5')\nmobilenet_model.save('mobilenet_finall.h5')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T17:47:47.045145Z","iopub.status.idle":"2025-04-25T17:47:47.045351Z","shell.execute_reply.started":"2025-04-25T17:47:47.045253Z","shell.execute_reply":"2025-04-25T17:47:47.045261Z"}},"outputs":[],"execution_count":null}]}